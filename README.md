# ğŸ§  **RAG Course Reader â€“ End-to-End LangChain Pipeline**

> **RAG Course Reader** lÃ  há»‡ thá»‘ng **Retrieval-Augmented Generation (RAG)** giÃºp **Ä‘á»c, hiá»ƒu vÃ  trÃ­ch dáº«n chÃ­nh xÃ¡c ná»™i dung tÃ i liá»‡u khÃ³a há»c** (PDF, Markdown, blog, syllabus, ghi chÃº há»c táº­p, v.v.).  
>  
> Dá»± Ã¡n Ä‘Æ°á»£c xÃ¢y dá»±ng theo kiáº¿n trÃºc **modular end-to-end**, dá»… má»Ÿ rá»™ng, dá»… giÃ¡m sÃ¡t vÃ  triá»ƒn khai á»Ÿ mÃ´i trÆ°á»ng **production-ready**.

---

## ğŸ¯ **Má»¥c tiÃªu**

- XÃ¢y dá»±ng **pipeline RAG hoÃ n chá»‰nh** tá»« *Ingestion â†’ Evaluation*  
- Cho phÃ©p ngÆ°á»i há»c **truy váº¥n kiáº¿n thá»©c khÃ³a há»c** vÃ  nháº­n cÃ¢u tráº£ lá»i cÃ³ **trÃ­ch dáº«n chÃ­nh xÃ¡c**  
- TÃ­ch há»£p cÃ¡c thÃ nh pháº§n nÃ¢ng cao: **Monitoring, Caching, Reranking, Guardrails, Multi-tenant dataset**  
- Há»— trá»£ cáº£ **OpenAI** vÃ  **HuggingFace open-source models**

---

## âš™ï¸ **Pipeline tá»•ng thá»ƒ**

```mermaid
graph LR
    A[ğŸ“¥ Ingestion<br/>Thu tháº­p dá»¯ liá»‡u] --> 
    B[ğŸ§¹ Preprocess<br/>LÃ m sáº¡ch & chuáº©n hÃ³a] --> 
    C[âœ‚ï¸ Chunk / Embed<br/>Cáº¯t vÃ  sinh embedding] --> 
    D[ğŸ’¾ Index<br/>LÆ°u vÃ o Vector Store] --> 
    E[ğŸ” Retrieve<br/>Truy xuáº¥t top-k Ä‘oáº¡n liÃªn quan] --> 
    F[âš–ï¸ Rerank<br/>Cháº¥m Ä‘iá»ƒm Ä‘á»™ liÃªn quan] --> 
    G[ğŸ§  Generate<br/>Sinh cÃ¢u tráº£ lá»i báº±ng LLM] --> 
    H[ğŸ”— Cite<br/>Gáº¯n trÃ­ch dáº«n nguá»“n] --> 
    I[ğŸ§¾ Evaluate<br/>ÄÃ¡nh giÃ¡ báº±ng RAGAS] --> 
    J[ğŸ“Š Monitor<br/>Theo dÃµi báº±ng Prometheus / Grafana]

```


| BÆ°á»›c | MÃ´ táº£ |
|------|--------|
| **Ingestion** | Thu tháº­p dá»¯ liá»‡u tá»« web, sitemap, hoáº·c file (PDF, Markdown, TXT) |
| **Preprocess** | LÃ m sáº¡ch HTML, chuáº©n hÃ³a Markdown, loáº¡i trÃ¹ng láº·p |
| **Chunk/Embed** | Cáº¯t Ä‘oáº¡n vÄƒn báº£n vÃ  sinh embedding (MiniLM / E5) |
| **Index** | LÆ°u vÃ o vectorstore (Chroma, FAISS, PGVector, Weaviate) |
| **Retrieve** | Truy xuáº¥t top-k Ä‘oáº¡n liÃªn quan |
| **Rerank** | Cháº¥m Ä‘iá»ƒm láº¡i Ä‘á»™ liÃªn quan (CrossEncoder / BGE) |
| **Generate** | Táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn ngá»¯ cáº£nh |
| **Cite** | Gáº¯n trÃ­ch dáº«n tá»± Ä‘á»™ng [^1] vÃ  tooltip HTML |
| **Evaluate** | ÄÃ¡nh giÃ¡ báº±ng RAGAS (faithfulness, relevance, recall) |
| **Monitor** | Theo dÃµi báº±ng Prometheus, Grafana, Langfuse |

---

## ğŸ—‚ **Cáº¥u trÃºc thÆ° má»¥c**

```bash
rag-course/
â”œâ”€ .env.example
â”œâ”€ docker-compose.yml
â”œâ”€ Dockerfile
â”œâ”€ requirements.txt
â”œâ”€ README.md
â”‚
â”œâ”€ data/
â”‚  â”œâ”€ raw/          # Dá»¯ liá»‡u gá»‘c (PDF, HTML, Markdown)
â”‚  â”œâ”€ processed/    # Sau khi chuáº©n hÃ³a
â”‚  â””â”€ eval/         # Bá»™ dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ RAGAS
â”‚
â”œâ”€ storage/
â”‚  â””â”€ chroma/       # Vectorstore (multi-tenant)
â”‚
â”œâ”€ monitoring/      # Prometheus + Grafana config
â”‚  â”œâ”€ prometheus/prometheus.yml
â”‚  â””â”€ grafana/
â”‚     â”œâ”€ provisioning/
â”‚     â”‚  â”œâ”€ datasources/datasource.yml
â”‚     â”‚  â””â”€ dashboards/dashboards.yml
â”‚     â””â”€ dashboards/rag-overview.json
â”‚
â”œâ”€ src/
â”‚  â”œâ”€ api.py              # FastAPI endpoints
â”‚  â”œâ”€ ingestion.py        # Thu tháº­p dá»¯ liá»‡u
â”‚  â”œâ”€ preprocess.py       # Chuáº©n hÃ³a vÃ  loáº¡i trÃ¹ng láº·p
â”‚  â”œâ”€ embed_index.py      # Chunk + embed + index
â”‚  â”œâ”€ hybrid_retriever.py # Hybrid BM25 + Dense retriever
â”‚  â”œâ”€ reranker.py         # CrossEncoder / BGE reranker
â”‚  â”œâ”€ generate.py         # Retrieve â†’ Rerank â†’ Generate â†’ Cite
â”‚  â”œâ”€ cache.py            # Redis Semantic Cache
â”‚  â”œâ”€ judge.py            # LLM-as-a-Judge (Hallucination check)
â”‚  â”œâ”€ evaluate.py         # RAGAS evaluation
â”‚  â”œâ”€ observability.py    # Langfuse + OpenTelemetry setup
â”‚  â”œâ”€ monitor.py          # Prometheus metrics
â”‚  â””â”€ config.py           # Cáº¥u hÃ¬nh há»‡ thá»‘ng
â”‚
â””â”€ scripts/
   â”œâ”€ ingest_urls.yaml
   â””â”€ run_api.sh
```

---

## ğŸ§° **CÃ´ng nghá»‡ chÃ­nh**

| ThÃ nh pháº§n | CÃ´ng nghá»‡ |
|-------------|------------|
| Framework | LangChain v0.3+ (core / community / openai / huggingface) |
| LLMs | GPT-4o, Mixtral, Mistral-7B, Zephyr |
| Embeddings | MiniLM, multilingual-e5, nomic-embed-text |
| Vector Store | Chroma (persist) + Elasticsearch (BM25 hybrid) |
| Cache | Redis Semantic Cache |
| Guardrails | LLM-as-a-Judge |
| Monitoring | Prometheus + Grafana |
| Observability | Langfuse + OpenTelemetry |
| Evaluation | RAGAS |
| API | FastAPI + Uvicorn |
| Container | Docker Compose |

---

## ğŸ§© **TÃ­nh nÄƒng ná»•i báº­t**

âœ… Hybrid Retriever â€“ Káº¿t há»£p BM25 (Elasticsearch) + Dense retriever (Chroma)  
âœ… Chunking thÃ´ng minh â€“ MarkdownHeaderTextSplitter giá»¯ nguyÃªn cáº¥u trÃºc chÆ°Æ¡ng/má»¥c  
âœ… Redis Semantic Cache â€“ LÆ°u cache theo má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng ngá»¯ nghÄ©a  
âœ… Guardrails â€“ DÃ¹ng LLM thá»© hai kiá»ƒm tra hallucination  
âœ… Observability â€“ Theo dÃµi qua Langfuse â†’ Prometheus / Grafana  
âœ… Citations Ä‘áº¹p â€“ TrÃ­ch dáº«n HTML kÃ¨m tooltip tá»« nguá»“n gá»‘c  
âœ… Multi-tenant VectorStore â€“ Há»— trá»£ nhiá»u dataset khÃ³a há»c riÃªng biá»‡t  

---

## âš™ï¸ **CÃ i Ä‘áº·t**

### 1ï¸âƒ£ Clone vÃ  thiáº¿t láº­p mÃ´i trÆ°á»ng

```bash
git clone https://github.com/<yourname>/rag-course.git
cd rag-course
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
```

> YÃªu cáº§u: Python â‰¥ 3.10, Docker â‰¥ 24, docker-compose â‰¥ 2.20

---

### 2ï¸âƒ£ Cháº¡y full stack báº±ng Docker Compose

```bash
docker compose up -d --build
```

| Service | Port | MÃ´ táº£ |
|----------|------|-------|
| rag | 8000 | FastAPI API |
| redis | 6379 | Semantic Cache |
| elasticsearch | 9200 | BM25 Retriever |
| prometheus | 9090 | Metrics Collector |
| grafana | 3000 | Dashboard Visualization |

Truy cáº­p:

- ğŸ§© FastAPI Docs: http://localhost:8000/docs  
- ğŸ“ˆ Prometheus: http://localhost:9090  
- ğŸ“Š Grafana: http://localhost:3000 (admin/admin)

---

### ğŸ”‘ Cáº¥u hÃ¬nh .env

```bash
PROVIDER=openai
OPENAI_API_KEY=sk-...
HF_TOKEN=hf_...

EMBEDDING_MODEL=intfloat/multilingual-e5-large
RERANKER_MODEL=BAAI/bge-reranker-v2-m3
OPENAI_MODEL=gpt-4o-mini
CHROMA_DIR=./storage/chroma

# Hybrid retriever
ES_URL=http://elasticsearch:9200
ES_INDEX=rag_bm25
HYBRID_ALPHA=0.5

# Cache
REDIS_URL=redis://redis:6379/0
CACHE_TTL_SEC=3600

# Observability
ENABLE_LANGFUSE=false
ENABLE_OTEL=false
```

---

## ğŸ§  **Sá»­ dá»¥ng**

### ğŸª¶ Ingest dá»¯ liá»‡u

```bash
curl -X POST http://localhost:8000/ingest
```

### ğŸ’¬ Äáº·t cÃ¢u há»i

```bash
curl -X POST http://localhost:8000/ask   -H "Content-Type: application/json"   -d '{"question":"Æ¯u Ä‘iá»ƒm cá»§a RAG so vá»›i fine-tune lÃ  gÃ¬?"}'
```

Tráº£ vá»:

```json
{
  "answer": "RAG giÃºp giáº£m chi phÃ­ huáº¥n luyá»‡n vÃ  dá»… cáº­p nháº­t dá»¯ liá»‡u má»›i [^1].",
  "answer_html": "RAG giÃºp giáº£m chi phÃ­ huáº¥n luyá»‡n...<sup title='TrÃ­ch Ä‘oáº¡n nguá»“n'>[1]</sup>",
  "sources": [
    {"source": "https://deeplearning.ai/short-courses/"},
    {"source": "https://www.langchain.com/blog"}
  ]
}
```

---

## ğŸ“Š **GiÃ¡m sÃ¡t há»‡ thá»‘ng**

### Prometheus

Truy cáº­p: http://localhost:9090

Metric chÃ­nh:
- rag_requests_total
- rag_retrieval_seconds
- rag_generation_seconds

### Grafana

Truy cáº­p: http://localhost:3000  
Dashboard: RAG Overview  
Theo dÃµi:
- Request rate
- Retrieval & Generation latency (p50/p90)
- PhÃ¢n tÃ­ch theo instance

---

## ğŸ§¾ **ÄÃ¡nh giÃ¡ báº±ng RAGAS**

Chuáº©n bá»‹ dá»¯ liá»‡u:

```csv
question,answer
"What is LangChain?","A framework for building LLM applications."
"Which embedding model is used?","sentence-transformers/all-MiniLM-L6-v2"
```

Cháº¡y Ä‘Ã¡nh giÃ¡:

```bash
python -m src.evaluate data/eval/dev.csv
```

Káº¿t quáº£ gá»“m:
- context_precision
- context_recall
- faithfulness
- answer_relevancy

---

## ğŸ” **Theo dÃµi & Quan sÃ¡t**

- /metrics â†’ Xuáº¥t Prometheus metrics  
- Langfuse â†’ Theo dÃµi trace tá»«ng request  
- OpenTelemetry â†’ Gá»­i trace Ä‘áº¿n Tempo / OTLP collector  

---

## ğŸš€ **HÆ°á»›ng má»Ÿ rá»™ng**

| Module | MÃ´ táº£ |
|---------|--------|
| ğŸ§­ Retriever nÃ¢ng cao | ThÃªm PGVector, Weaviate, hoáº·c Vectara |
| âš¡ Rerank nÃ¢ng cao | DÃ¹ng ColBERT hoáº·c LLM Reranker |
| ğŸ§® Caching tá»‘i Æ°u | Redis Cluster hoáº·c Memgraph Cache |
| ğŸ”’ Guardrails | Káº¿t há»£p LLM-as-a-Judge vá»›i rule-based filter |
| ğŸ“ˆ Observability | Langfuse SaaS + Tempo tracing |
| ğŸ§  Fine-tuning | Táº­n dá»¥ng dá»¯ liá»‡u RAG Ä‘á»ƒ fine-tune domain model |

---

## ğŸ‘¨â€ğŸ’» **TÃ¡c giáº£**

Trá»‹nh VÄƒn Giang  
ğŸ“ Hanoi University of Science and Technology (HUST)  
âœ‰ï¸ giangnbhust@gmail.com  

Version: 1.0.0 (2025-10)

---

ğŸ›  **Cháº¡y dá»± Ã¡n trÃªn terminal**

- Cháº¡y local (virtualenv, cho phÃ¡t triá»ƒn)
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
cp .env.example .env     # chá»‰nh .env theo mÃ´i trÆ°á»ng cá»§a báº¡n
uvicorn src.api:app --host 0.0.0.0 --port 8000 --reload
```

- Cháº¡y production nhanh vá»›i uvicorn (2 workers)
```bash
uvicorn src.api:app --host 0.0.0.0 --port 8000 --workers 2
```

- Cháº¡y báº±ng Docker (build image tá»« dockerfile)
```bash
docker build -t rag-course:latest -f dockerfile .
docker run -p 8000:8000 --env-file .env --rm rag-course:latest
```

- Cháº¡y toÃ n bá»™ stack báº±ng Docker Compose (náº¿u cÃ³ docker-compose.yml)
```bash
docker compose up -d --build
# logs: docker compose logs -f
# dá»«ng: docker compose down
```

- Script helper (náº¿u tá»“n táº¡i scripts/run_api.sh)
```bash
bash ./scripts/run_api.sh
```

Ghi chÃº ngáº¯n:
- Äáº£m báº£o Ä‘áº·t biáº¿n mÃ´i trÆ°á»ng trong .env (OPENAI_API_KEY, HF_TOKEN, CHROMA_DIR, v.v.).  
- Cá»•ng máº·c Ä‘á»‹nh API: http://localhost:8000/docs